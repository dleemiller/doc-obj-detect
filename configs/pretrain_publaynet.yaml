# D-FINE Pretraining configuration for PubLayNet dataset
# ConvNeXt-Large DINOv3 backbone + D-FINE detector head (3 stride levels)

model:
  backbone: "convnext_large.dinov3_lvd1689m"  # ConvNeXt-Large DINOv3 (~200M params)
  architecture: "dfine_xlarge"  # D-FINE XLarge architecture (see configs/architectures/dfine_xlarge.yaml)
  num_classes: 5  # PubLayNet: text, title, list, table, figure
  use_pretrained_backbone: true  # Keep ConvNeXt-DINOv3 weights (1.7B images, SOTA features)
  freeze_backbone: true  # Let the decoder stabilize against frozen ConvNeXt features
  freeze_backbone_epochs: 50  # Unfreeze after 2 epochs for full end-to-end training

dfine:
  # Backbone-specific configuration (depends on chosen backbone)
  # Using 3 levels at strides {8, 16, 32} for memory efficiency
  # Note: Must use consecutive stages for D-FINE FPN (requires 2x downsampling between levels)
  encoder_in_channels: [384, 768, 1536]  # ConvNeXt-Large channel dimensions for stages 1, 2, 3
  feat_strides: [8, 16, 32]  # Feature pyramid strides
  num_feature_levels: 3  # 3 levels for standard D-FINE configuration
  backbone_kwargs:
    out_indices: [1, 2, 3]  # Extract from stages 1, 2, 3 (C3, C4, C5)

  # Architecture-specific parameters loaded from configs/architectures/dfine_xlarge.yaml
  # Can override here if needed, but defaults from architecture file are recommended

data:
  dataset: "publaynet"
  train_split: "train"
  val_split: "validation"  # PubLayNet uses 'validation' not 'val'
  image_size: 640  # Standard document detection size
  batch_size: 64  # Trimmed from the 32-image D-FINE recipe to leave VRAM for the C2 feature map
  max_eval_samples: 1000
  num_workers: 6  # Optimized for data loading (max per RAM constraints)
  pin_memory: true  # Faster GPU transfer
  prefetch_factor: 3  # Increased to improve GPU utilization
  persistent_workers: true  # Keep workers alive between epochs for better throughput

augmentation:
  # Multi-scale training for better scale invariance and small object detection
  multi_scale_sizes: [576, 608, 640, 672]
  max_long_side: 1024

  # Flip augmentations (essential for layout detection - ICDAR 2023 & DocLayout-YOLO)
  horizontal_flip: 0.5  # Standard horizontal flip (matches papers)
  vertical_flip: 0.5   # Increased to match DocLayout-YOLO (handles varied text orientations)

  # Random cropping - ENABLED (DocLayout-YOLO's highest probability augmentation)
  random_crop:
    probability: 0.5  # Enabled per DocLayout-YOLO research (highest impact augmentation)
    area_min: 0.6     # Keep 50-90% of page (preserves significant context)
    area_max: 0.95     # Forces model to detect objects at varying spatial scales

  # Mosaic augmentation - DISABLED (breaks document layout coherence per YOLO11-OBB study)
  mosaic:
    probability: 0.0  # Disabled - research shows mosaic harmful for document object detection
    disable_after_epoch: 6  # (inactive)

  # Geometric augmentations - ROTATION DISABLED (visual inspection confirmed bbox misalignment)
  rotate_limit: 1  # DISABLED - even ±2° causes bbox/content misalignment with axis-aligned boxes
  rotate_prob: 0.0  # DISABLED - would harm training quality with incorrect labels
  perspective:
    probability: 0.0  # Disabled for pretraining (conservative approach)
    scale_min: 0.02
    scale_max: 0.05

  # Photometric augmentation settings (applied when photometric is chosen vs Augraphy)
  # Individual probabilities hardcoded in code for simplicity (brightness: 0.5, blur/compression/noise: 0.3)
  # To control overall photometric vs Augraphy split, use augraphy.choice_probability below
  brightness_contrast:
    limit: 0.15  # ±20% brightness/contrast variation
  blur:
    blur_limit: 2  # Max blur kernel size
  compression:
    quality_min: 75  # JPEG quality range
    quality_max: 100
  noise:
    std_min: 0.0  # Gaussian noise standard deviation
    std_max: 0.01
  elastic:
    probability: 0.2
    alpha: 30
    sigma: 5

  # Sobel edge extraction (optional - disabled by default)
  sobel_edge:
    enabled: false  # Set to true to enable edge enhancement
    blend_alpha: 0.2  # 20% edge, 80% original (if enabled)

  # Augraphy: Realistic document degradation (paper texture, ink effects, scanning artifacts)
  augraphy:
    enabled: true

    # DEGRADATION CHOICE (photometric OR Augraphy - mutually exclusive)
    choice_probability: 0.5   # 0.5 = 50% use Augraphy, 50% use photometric

    # Per-phase probabilities (control Augraphy's internal OneOf groups)
    ink_probability: 0.5      # Ink phase: InkBleed OR InkMottling OR InkColorSwap
    paper_probability: 0.5    # Paper phase: ColorPaper OR BrightnessTexturize + artifacts
    post_probability: 0.5     # Post phase: Brightness OR Gamma OR Faxify (prevents stacking)

training:
  # Training schedule: 12 epochs to match SOTA paper
  # Cosine LR provides natural "precision tail" for final mAP gains
  num_train_epochs: 12

  # Learning rates follow the D-FINE schedule scaled to batch_size=16 (base 2.5e-4 → 1.25e-4)
  learning_rate: 2.5e-4  # Head LR after linear scaling from the 32-image reference run
  backbone_lr_multiplier: 0.01  # Backbone LR = 1% of head LR (1.25e-6) to preserve DINOv3 features

  # Optimizer settings
  optim: "adamw_torch_fused"  # Standard AdamW (D-FINE uses standard, not 8-bit)
  weight_decay: 1.25e-4  # Matches the official D-FINE configs; larger values over-regularize

  # Warmup and scheduling
  lr_scheduler_type: "cosine_with_min_lr"
  warmup_ratio: 0.08  # 8% of total training (was 5000 steps, too long for rapid convergence)
  lr_scheduler_kwargs:
    min_lr: 2.5e-5  # Min LR = base_lr / 10 (precision tail for final mAP gains)

  # Gradient settings
  gradient_accumulation_steps: 1
  max_grad_norm: 0.1  # D-FINE standard (global fallback, not used when separate norms specified)
    #backbone_max_grad_norm: 0.1  # Separate clipping prevents starvation; LR multiplier (0.01) controls update magnitude
    #head_max_grad_norm: 0.1  # D-FINE standard for encoder/decoder/detection head

  # Mixed precision
  bf16: true

  # Exponential Moving Average (EMA) - D-FINE standard
  ema:
    enabled: true  # Enable EMA for better evaluation metrics
    decay: 0.9999  # D-FINE default
    warmup_steps: 1000  # D-FINE default
    use_for_eval: true  # Use EMA weights for evaluation

  # Checkpointing and evaluation
  save_steps: 500
  eval_steps: 500
  logging_steps: 5
  eval_strategy: "steps"
  save_strategy: "steps"
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "map"
  greater_is_better: true
  push_to_hub: false

output:
  output_dir: "outputs/pretrain_publaynet_dfine_phase2"
  checkpoint_dir: "outputs/pretrain_publaynet_dfine_phase2/checkpoints"
  log_dir: "outputs/pretrain_publaynet_dfine_phase2/logs"
  run_name: "multiscale_lr1.25e-4_bs16_12ep"  # Unique name for TensorBoard (or use timestamp if null)
