# Fine-tuning configuration for DocLayNet dataset
# Use --load flag to load pretrained PubLayNet model:
#   uv run train --config configs/finetune_doclaynet.yaml --load outputs/pretrain_publaynet/final_model_ema

model:
  backbone: "convnext_large.dinov3_lvd1689m"  # ConvNeXt-Large DINOv3
  architecture: dfine_xlarge  # D-FINE XLarge architecture
  num_classes: 11  # DocLayNet classes (caption, footnote, formula, list-item, page-footer, page-header, picture, section-header, table, text, title)
  use_pretrained_backbone: true  # Keep ConvNeXt-DINOv3 pretrained weights
  freeze_backbone: false  # Fine-tune end-to-end (DocLayNet has different layout patterns than PubLayNet)
  freeze_backbone_epochs: 0  # No freezing for fine-tuning

dfine:
  # Backbone-specific configuration (ConvNeXt-Large)
  encoder_in_channels: [384, 768, 1536]  # ConvNeXt-Large channel dimensions
  feat_strides: [8, 16, 32]
  num_feature_levels: 3
  backbone_kwargs:
    out_indices: [1, 2, 3]

data:
  dataset: "doclaynet"
  train_split: "train"
  val_split: "val"
  image_size: 512
  batch_size: 8
  num_workers: 8

augmentation:
  multi_scale_sizes: [480, 512, 544, 576, 608, 640]
  max_long_side: 928

  # Flip augmentations (essential for layout detection - ICDAR 2023 & DocLayout-YOLO)
  horizontal_flip: 0.5  # Standard horizontal flip (matches papers)
  vertical_flip: 0.5   # Increased to match DocLayout-YOLO (handles varied text orientations)

  # Random cropping (DocLayout-YOLO: 0.7 probability, area 0.5-0.9)
  random_crop:
    probability: 0.7  # High probability for local feature learning
    area_min: 0.5     # Minimum crop area as fraction of original
    area_max: 0.9     # Maximum crop area

  # Mosaic augmentation (reduced for fine-tuning - model already learned from pretraining)
  mosaic:
    probability: 0.3  # Lower than pretraining (0.5) - conservative fine-tuning
    disable_after_epoch: 5  # Disable early (out of 20 total) to focus on real DocLayNet patterns

  # Geometric augmentations
  rotate_limit: 5  # ICDAR winners used 5Â°
  rotate_prob: 0.5
  perspective:
    probability: 0.3  # Enabled for fine-tuning (more aggressive)
    scale_min: 0.02
    scale_max: 0.05

  # Photometric augmentations (aligned with DocLayout-YOLO)
  brightness_contrast:
    limit: 0.2
    probability: 0.5  # Matches DocLayout-YOLO
  blur:
    probability: 0.3  # Simulates resolution issues and blur
    blur_limit: 3
  compression:
    probability: 0.3  # JPEG artifact robustness
    quality_min: 75
    quality_max: 100
  noise:
    probability: 0.3  # Increased to match DocLayout-YOLO's Gaussian noise
    std_min: 0.0
    std_max: 0.01
  elastic:
    probability: 0.2  # Enabled for fine-tuning (simulates jitter/distortion)
    alpha: 30
    sigma: 5

training:
  # Fine-tuning schedule
  num_train_epochs: 20
  learning_rate: 5.0e-5  # Lower LR for fine-tuning
  backbone_lr_multiplier: 0.1  # Backbone LR = 10% of head LR (higher than pretraining since we're fine-tuning)
  weight_decay: 1.0e-4
  warmup_ratio: 0.05
  lr_scheduler_type: "cosine_with_min_lr"
  lr_scheduler_kwargs:
    min_lr: 5.0e-6  # Min LR = base_lr / 10

  # Gradient settings
  gradient_accumulation_steps: 1
  max_grad_norm: 0.1
  backbone_max_grad_norm: 0.1
  head_max_grad_norm: 0.1

  # Mixed precision
  bf16: true

  # EMA for better evaluation
  ema:
    enabled: true
    decay: 0.9999
    warmup_steps: 500
    use_for_eval: true

  # Checkpointing and evaluation
  save_steps: 500
  eval_steps: 500
  logging_steps: 50
  eval_strategy: "steps"
  save_strategy: "steps"
  save_total_limit: 3
  load_best_model_at_end: true
  metric_for_best_model: "map"
  greater_is_better: true
  push_to_hub: false

output:
  output_dir: "outputs/finetune_doclaynet"
  checkpoint_dir: "outputs/finetune_doclaynet/checkpoints"
  log_dir: "outputs/finetune_doclaynet/logs"
